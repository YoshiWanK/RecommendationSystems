{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXQzH0nC5JtP"
      },
      "source": [
        "# **Project: Amazon Product Recommendation System**\n",
        "\n",
        "\n",
        "Welcome to the project on Recommendation Systems. We will work with the Amazon product reviews dataset for this project. The dataset contains ratings of different electronic products. It does not include information about the products or reviews to avoid bias while building the model.\n",
        "\n",
        "--------------\n",
        "## **Context:**\n",
        "--------------\n",
        "\n",
        "Today, information is growing exponentially with volume, velocity and variety throughout the globe. This has lead to information overload, and too many choices for the consumer of any business. It represents a real dilemma for these consumers and they often turn to denial. Recommender Systems are one of the best tools that help recommending products to consumers while they are browsing online. Providing personalized recommendations which is most relevant for the user is what's most likely to keep them engaged and help business.\n",
        "\n",
        "E-commerce websites like Amazon, Walmart, Target and Etsy use different recommendation models to provide personalized suggestions to different users. These companies spend millions of dollars to come up with algorithmic techniques that can provide personalized recommendations to their users.\n",
        "\n",
        "Amazon, for example, is well-known for its accurate selection of recommendations in its online site. Amazon's recommendation system is capable of intelligently analyzing and predicting customers' shopping preferences in order to offer them a list of recommended products. Amazon's recommendation algorithm is therefore a key element in using AI to improve the personalization of its website. For example, one of the baseline recommendation models that Amazon uses is item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real-time.\n",
        "\n",
        "----------------\n",
        "## **Objective:**\n",
        "----------------\n",
        "\n",
        "You are a Data Science Manager at Amazon, and have been given the task of building a recommendation system to recommend products to customers based on their previous ratings for other products. You have a collection of labeled data of Amazon reviews of products. The goal is to extract meaningful insights from the data and build a recommendation system that helps in recommending products to online consumers.\n",
        "\n",
        "-----------------------------\n",
        "## **Dataset:**\n",
        "-----------------------------\n",
        "\n",
        "The Amazon dataset contains the following attributes:\n",
        "\n",
        "- **userId:** Every user identified with a unique id\n",
        "- **productId:** Every product identified with a unique id\n",
        "- **Rating:** The rating of the corresponding product by the corresponding user\n",
        "- **timestamp:** Time of the rating. We **will not use this column** to solve the current problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmdPxJ2Q7W7p"
      },
      "source": [
        "**Note:** The code has some user defined functions that will be usefull while making recommendations and measure model performance, you can use these functions or can create your own functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoRfgjS2yekq"
      },
      "source": [
        "Sometimes, the installation of the surprise library, which is used to build recommendation systems, faces issues in Jupyter. To avoid any issues, it is advised to use **Google Colab** for this project.\n",
        "\n",
        "Let's start by mounting the Google drive on Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ0YAszcT4zK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634b90d4-58f1-4a9f-ec0c-4ff16c86aecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ibk07-Cyekt"
      },
      "source": [
        "**Installing surprise library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05HQoiZYlsbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c444c35-5dca-4f07-b46d-75ee422d8367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.13.1)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357295 sha256=e4a9a554eb3dcc16866114a235b2664c143e135d4aa436934ee5184433c0e2c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fIt4jcFIm76"
      },
      "source": [
        "## **Importing the necessary libraries and overview of the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzu2P-TT5JtP"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from collections import defaultdict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrXYJAv95JtP"
      },
      "source": [
        "### **Loading the data**\n",
        "- Import the Dataset\n",
        "- Add column names ['user_id', 'prod_id', 'rating', 'timestamp']\n",
        "- Drop the column timestamp\n",
        "- Copy the data to another DataFrame called **df**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGb-Hk1B5JtP"
      },
      "outputs": [],
      "source": [
        "# Load Data\n",
        "df = pd.read_csv('/content/drive/MyDrive/ratings_Electronics.csv', header = None)\n",
        "\n",
        "df.columns = ['user_id', 'prod_id', 'rating', 'timestamp']\n",
        "\n",
        "df = df.drop('timestamp', axis = 1)\n",
        "\n",
        "df_copy = df.copy(deep = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVQnSG5g_9uX"
      },
      "source": [
        "**As this dataset is very large and has 7,824,482 observations, it is not computationally possible to build a model using this. Moreover, many users have only rated a few products and also some products are rated by very few users. Hence, we can reduce the dataset by considering certain logical assumptions.**\n",
        "\n",
        "Here, we will be taking users who have given at least 50 ratings, and the products that have at least 5 ratings, as when we shop online we prefer to have some number of ratings of a product."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yt9W7Q32EQQ"
      },
      "outputs": [],
      "source": [
        "# Get the column containing the users\n",
        "users = df.user_id\n",
        "\n",
        "# Create a dictionary from users to their number of ratings\n",
        "ratings_count = dict()\n",
        "\n",
        "for user in users:\n",
        "\n",
        "    # If we already have the user, just add 1 to their rating count\n",
        "    if user in ratings_count:\n",
        "        ratings_count[user] += 1\n",
        "\n",
        "    # Otherwise, set their rating count to 1\n",
        "    else:\n",
        "        ratings_count[user] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19XB60dq2EQR"
      },
      "outputs": [],
      "source": [
        "# We want our users to have at least 50 ratings to be considered\n",
        "RATINGS_CUTOFF = 50\n",
        "\n",
        "remove_users = []\n",
        "\n",
        "for user, num_ratings in ratings_count.items():\n",
        "    if num_ratings < RATINGS_CUTOFF:\n",
        "        remove_users.append(user)\n",
        "\n",
        "df = df.loc[ ~ df.user_id.isin(remove_users)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33UzK1D82EQS"
      },
      "outputs": [],
      "source": [
        "# Get the column containing the products\n",
        "prods = df.prod_id\n",
        "\n",
        "# Create a dictionary from products to their number of ratings\n",
        "ratings_count = dict()\n",
        "\n",
        "for prod in prods:\n",
        "\n",
        "    # If we already have the product, just add 1 to its rating count\n",
        "    if prod in ratings_count:\n",
        "        ratings_count[prod] += 1\n",
        "\n",
        "    # Otherwise, set their rating count to 1\n",
        "    else:\n",
        "        ratings_count[prod] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6YE-lUp2EQT"
      },
      "outputs": [],
      "source": [
        "# We want our item to have at least 5 ratings to be considered\n",
        "RATINGS_CUTOFF = 5\n",
        "\n",
        "remove_users = []\n",
        "\n",
        "for user, num_ratings in ratings_count.items():\n",
        "    if num_ratings < RATINGS_CUTOFF:\n",
        "        remove_users.append(user)\n",
        "\n",
        "df_final = df.loc[~ df.prod_id.isin(remove_users)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aL1JZ00o5JtQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3ea59c7a-3aa0-4916-dc2d-56681bbb9d61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             user_id     prod_id  rating\n",
              "1310  A3LDPF5FMB782Z  1400501466     5.0\n",
              "1322  A1A5KUIIIHFF4U  1400501466     1.0\n",
              "1335  A2XIOXRRYX0KZY  1400501466     3.0\n",
              "1451   AW3LX47IHPFRL  1400501466     5.0\n",
              "1456  A1E3OB6QMBKRYZ  1400501466     1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5d8462d-502b-4abb-b7ba-eaef524e84fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>prod_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1310</th>\n",
              "      <td>A3LDPF5FMB782Z</td>\n",
              "      <td>1400501466</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1322</th>\n",
              "      <td>A1A5KUIIIHFF4U</td>\n",
              "      <td>1400501466</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>A2XIOXRRYX0KZY</td>\n",
              "      <td>1400501466</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1451</th>\n",
              "      <td>AW3LX47IHPFRL</td>\n",
              "      <td>1400501466</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>A1E3OB6QMBKRYZ</td>\n",
              "      <td>1400501466</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5d8462d-502b-4abb-b7ba-eaef524e84fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5d8462d-502b-4abb-b7ba-eaef524e84fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5d8462d-502b-4abb-b7ba-eaef524e84fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1c290533-0b57-46c4-90e7-529edeefb321\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c290533-0b57-46c4-90e7-529edeefb321')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1c290533-0b57-46c4-90e7-529edeefb321 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final",
              "summary": "{\n  \"name\": \"df_final\",\n  \"rows\": 65290,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1540,\n        \"samples\": [\n          \"A1VJ0V58N0698J\",\n          \"A14X244VGHWPSX\",\n          \"A14JBDSWKPKTZA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prod_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5689,\n        \"samples\": [\n          \"B005EOWBHC\",\n          \"B00BB72WX4\",\n          \"B00B9AB26G\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9889148020336815,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0,\n          2.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Print a few rows of the imported dataset\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuPoy_XfxhXZ"
      },
      "source": [
        "## **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0d0bWeG-sVB"
      },
      "source": [
        "### **Shape of the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyBVTRDTyek0"
      },
      "source": [
        "### **Check the number of rows and columns and provide observations.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJ4eQKaY5JtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7341b3b6-1473-4f75-8a6c-9e8e871e0acf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65290, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Check the number of rows and columns and provide observations\n",
        "df_final.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slp-fgWQ-sVD"
      },
      "source": [
        "**Write your observations here:** There are a significantly vastly more number of rows compared to just 3 columns making the data set very sparse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAMWm0nC-sVF"
      },
      "source": [
        "### **Data types**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVrgMkye5JtQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "ab3ccbec-0100-4d70-802e-87b90e707599"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user_id     object\n",
              "prod_id     object\n",
              "rating     float64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prod_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Check Data types and provide observations\n",
        "df_final.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4fOE02D-sVF"
      },
      "source": [
        "**Write your observations here:** Two of the three columns are of object type, but written numerically, and rating is of float type, but is actually categorical since there are only a set amount of numbers the rating variable can take."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTMpOROT-sVG"
      },
      "source": [
        "### **Checking for missing values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt-VEjMA5JtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ed44c7-60fd-44e4-d26d-4492fc02c99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "user_id    0\n",
            "prod_id    0\n",
            "rating     0\n",
            "dtype: int64\n",
            "\n",
            "No missing values found in the dataset.\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values present and provide observations\n",
        "missing_values = df_final.isnull().sum()\n",
        "\n",
        "print(\"Missing values in each column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Display columns that have missing values\n",
        "missing_values_columns = missing_values[missing_values > 0]\n",
        "\n",
        "if not missing_values_columns.empty:\n",
        "    print(\"\\nColumns with missing values:\")\n",
        "    print(missing_values_columns)\n",
        "else:\n",
        "    print(\"\\nNo missing values found in the dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMWuBNhI5JtR"
      },
      "source": [
        "**Write your observations here:** I didn't find any missing values for this data set so no additional work needs to be done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wETrCg48-sVG"
      },
      "source": [
        "### **Summary Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYm30MXR5JtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b858520b-2419-4cd5-e3df-d41909729fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary Statistics for 'rating' variable:\n",
            "count    65290.000000\n",
            "mean         4.294808\n",
            "std          0.988915\n",
            "min          1.000000\n",
            "25%          4.000000\n",
            "50%          5.000000\n",
            "75%          5.000000\n",
            "max          5.000000\n",
            "Name: rating, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Summary statistics of 'rating' variable and provide observations\n",
        "rating_summary = df_final['rating'].describe()\n",
        "\n",
        "# Display the summary statistics\n",
        "print(\"Summary Statistics for 'rating' variable:\")\n",
        "print(rating_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqW50EIJxhXc"
      },
      "source": [
        "**Write your observations here:** The average rating is relatively high at ~4.3 out of 5 stars with a moderately ranged standard deviation at around 1. The median is 5 stars showing a disproportionate amout of 5 stars compared to any other rating in the data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywyFrZIf5JtR"
      },
      "source": [
        "### **Checking the rating distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbqhbEVe-sVH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "328d1d87-7529-4c9c-dadf-9145c01a0683"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create the bar plot and provide observations\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='rating', data=df_final, palette='viridis')\n",
        "\n",
        "plt.title('Distribution of Ratings in df_final')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0jONrQv-sVH"
      },
      "source": [
        "**Write your observations here:** As follows from my previous observation, we do find that the most ratings are indeed 5 star ratings, having more 5 star ratings counted than all the other rating combined, with 4 star rating count being about half as much, and 1 to 3 star ratings being practically negligible in comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HefpLdLJxhXd"
      },
      "source": [
        "### **Checking the number of unique users and items in the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbSom7195JtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8adfc4bf-8ce3-45fb-a47f-c62d76223a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows in the data: 65290\n",
            "Number of unique user IDs: 1540\n",
            "Number of unique product IDs: 5689\n"
          ]
        }
      ],
      "source": [
        "# Number of total rows in the data and number of unique user id and product id in the data\n",
        "total_rows = df_final.shape[0]\n",
        "\n",
        "unique_user_ids = df_final['user_id'].nunique()\n",
        "unique_product_ids = df_final['prod_id'].nunique()\n",
        "\n",
        "# Results\n",
        "print(f\"Total number of rows in the data: {total_rows}\")\n",
        "print(f\"Number of unique user IDs: {unique_user_ids}\")\n",
        "print(f\"Number of unique product IDs: {unique_product_ids}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwgz6CUt-sVI"
      },
      "source": [
        "**Write your observations here:** We see that compared to total rows, neither user IDs are product IDs are completely unique across all of the rows, with about 1/50 of rows having unique user IDs and around 1/10 having unique product IDs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfDnhSS4-sVI"
      },
      "source": [
        "### **Users with the most number of ratings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7MX452q5JtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aefa3ac-2c43-4207-88a3-ef0dd38bd8df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Users Based on the Number of Ratings:\n",
            "user_id\n",
            "ADLVFFE4VBT8      295\n",
            "A3OXHLG6DIBRW8    230\n",
            "A1ODOGXEYECQQ8    217\n",
            "A36K2N527TXXJN    212\n",
            "A25C2M3QF9G7OQ    203\n",
            "A680RUE1FDO8B     196\n",
            "A22CW0ZHY3NJH8    193\n",
            "A1UQBFCERIP7VJ    193\n",
            "AWPODHOB4GFWL     184\n",
            "A3LGT6UZL99IW1    179\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Top 10 users based on the number of ratings\n",
        "user_rating_counts = df_final.groupby('user_id').size().sort_values(ascending=False)\n",
        "\n",
        "top_10 = user_rating_counts.head(10)\n",
        "\n",
        "# Display the top 10 users and their rating counts\n",
        "print(\"Top 10 Users Based on the Number of Ratings:\")\n",
        "print(top_10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X2w_jt9-sVI"
      },
      "source": [
        "**Write your observations here:** We see that most of the users in the top 10 greatly exceed the 1:50 ratio between rows and unique User IDs with all of them having triple digit numbers of ratings with the user that gave the most ratings even having ~300 total ratings!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnYTx-Ol-sVg"
      },
      "source": [
        "**Now that we have explored and prepared the data, let's build the first recommendation system.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xYGrGVy5JtS"
      },
      "source": [
        "## **Model 1: Rank Based Recommendation System**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxZTj1UPxhXh",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0216cf-36e3-455a-b220-db43c8d58958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First five records of the final_rating dataset:\n",
            "            average_rating  rating_count\n",
            "prod_id                                 \n",
            "B00LGQ6HL8             5.0             5\n",
            "B003DZJQQI             5.0            14\n",
            "B005FDXF2C             5.0             7\n",
            "B00I6CVPVC             5.0             7\n",
            "B00B9KOCYA             5.0             8\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average rating for each product\n",
        "average_rating_per_product = df_final.groupby('prod_id')['rating'].mean()\n",
        "\n",
        "# Calculate the count of ratings for each product\n",
        "count_rating_per_product = df_final.groupby('prod_id')['rating'].count()\n",
        "\n",
        "# Create a dataframe with calculated average and count of ratings\n",
        "final_rating = pd.DataFrame({\n",
        "    'average_rating': average_rating_per_product,\n",
        "    'rating_count': count_rating_per_product\n",
        "})\n",
        "# Sort the dataframe by average of ratings in the descending order\n",
        "final_rating = final_rating.sort_values(by='average_rating', ascending=False)\n",
        "\n",
        "# See the first five records of the \"final_rating\" dataset\n",
        "print(\"First five records of the final_rating dataset:\")\n",
        "print(final_rating.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKU__5s1xhXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee4665d-31ce-4119-e779-12bfcd4cce65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 products with at least 50 interactions, sorted by average rating:\n",
            "            average_rating  rating_count\n",
            "prod_id                                 \n",
            "B001TH7GUU        4.871795            78\n",
            "B003ES5ZUU        4.864130           184\n",
            "B0019EHU8G        4.855556            90\n",
            "B006W8U2MU        4.824561            57\n",
            "B000QUUFRW        4.809524            84\n",
            "B000HPV3RW        4.803922            51\n",
            "B001TH7GSW        4.803279            61\n",
            "B000BQ7GW8        4.777778            54\n",
            "B000N99BBC        4.772455           167\n",
            "B002WE6D44        4.770000           100\n"
          ]
        }
      ],
      "source": [
        "# Defining a function to get the top n products based on the highest average rating and minimum interactions\n",
        "def get_top_n_products(dataframe, n, min_interactions):\n",
        "    average_rating_per_product = dataframe.groupby('prod_id')['rating'].mean()\n",
        "    count_rating_per_product = dataframe.groupby('prod_id')['rating'].count()\n",
        "    final_rating = pd.DataFrame({\n",
        "        'average_rating': average_rating_per_product,\n",
        "        'rating_count': count_rating_per_product\n",
        "    })\n",
        "\n",
        "    filtered_rating = final_rating[final_rating['rating_count'] >= min_interactions]\n",
        "    sorted_rating = filtered_rating.sort_values(by='average_rating', ascending=False)\n",
        "    return sorted_rating.head(n)\n",
        "\n",
        "# Finding products with minimum number of interactions\n",
        "min_interactions = 50\n",
        "n = 10\n",
        "\n",
        "top_products = get_top_n_products(df_final, n, min_interactions)\n",
        "\n",
        "# Sorting values with respect to average rating\n",
        "print(f\"Top {n} products with at least {min_interactions} interactions, sorted by average rating:\")\n",
        "print(top_products)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8l6373PxhXi"
      },
      "source": [
        "### **Recommending top 5 products with 50 minimum interactions based on popularity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBxdLiM_xhXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8384f630-ca61-47b4-b079-7ee40d668e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 products with at least 50 interactions, sorted by average rating:\n",
            "            average_rating  rating_count\n",
            "prod_id                                 \n",
            "B001TH7GUU        4.871795            78\n",
            "B003ES5ZUU        4.864130           184\n",
            "B0019EHU8G        4.855556            90\n",
            "B006W8U2MU        4.824561            57\n",
            "B000QUUFRW        4.809524            84\n"
          ]
        }
      ],
      "source": [
        "print(f\"Top 5 products with at least 50 interactions, sorted by average rating:\")\n",
        "print(get_top_n_products(df_final, 5, 50))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9_xW_UMxhXj"
      },
      "source": [
        "### **Recommending top 5 products with 100 minimum interactions based on popularity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZgGZCUoxhXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fe34bc1-9259-4da6-9a6a-d926f4b56770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 products with at least 100 interactions, sorted by average rating:\n",
            "            average_rating  rating_count\n",
            "prod_id                                 \n",
            "B003ES5ZUU        4.864130           184\n",
            "B000N99BBC        4.772455           167\n",
            "B002WE6D44        4.770000           100\n",
            "B007WTAJTO        4.701220           164\n",
            "B002V88HFE        4.698113           106\n"
          ]
        }
      ],
      "source": [
        "print(f\"Top 5 products with at least 100 interactions, sorted by average rating:\")\n",
        "print(get_top_n_products(df_final, 5, 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL-m68a15JtT",
        "outputId": "69132b0f-8d3f-4798-f6a0-249e17a3c822"
      },
      "source": [
        "We have recommended the **top 5** products by using the popularity recommendation system. Now, let's build a recommendation system using **collaborative filtering.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJI5kiiGvOOK"
      },
      "source": [
        "## **Model 2: Collaborative Filtering Recommendation System**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skzc0N1_nVNB"
      },
      "source": [
        "### **Building a baseline user-user similarity based recommendation system**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Uo_MYMnVNB"
      },
      "source": [
        "- Below, we are building **similarity-based recommendation systems** using `cosine` similarity and using **KNN to find similar users** which are the nearest neighbor to the given user.  \n",
        "- We will be using a new library, called `surprise`, to build the remaining models. Let's first import the necessary classes and functions from this library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ1wEylUpexj"
      },
      "outputs": [],
      "source": [
        "# To compute the accuracy of models\n",
        "from surprise import accuracy\n",
        "\n",
        "# Class is used to parse a file containing ratings, data should be in structure - user ; item ; rating\n",
        "from surprise.reader import Reader\n",
        "\n",
        "# Class for loading datasets\n",
        "from surprise.dataset import Dataset\n",
        "\n",
        "# For tuning model hyperparameters\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "# For splitting the rating data in train and test datasets\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# For implementing similarity-based recommendation system\n",
        "from surprise.prediction_algorithms.knns import KNNBasic\n",
        "\n",
        "# For implementing matrix factorization based recommendation system\n",
        "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
        "\n",
        "# for implementing K-Fold cross-validation\n",
        "from surprise.model_selection import KFold\n",
        "\n",
        "# For implementing clustering-based recommendation system\n",
        "from surprise import CoClustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54MqVAtDTsnl"
      },
      "source": [
        "**Before building the recommendation systems, let's  go over some basic terminologies we are going to use:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsxb3xhnTsnl"
      },
      "source": [
        "**Relevant item:** An item (product in this case) that is actually **rated higher than the threshold rating** is relevant, if the **actual rating is below the threshold then it is a non-relevant item**.  \n",
        "\n",
        "**Recommended item:** An item that's **predicted rating is higher than the threshold is a recommended item**, if the **predicted rating is below the threshold then that product will not be recommended to the user**.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moyLUHCuTsnl"
      },
      "source": [
        "**False Negative (FN):** It is the **frequency of relevant items that are not recommended to the user**. If the relevant items are not recommended to the user, then the user might not buy the product/item. This would result in the **loss of opportunity for the service provider**, which they would like to minimize.\n",
        "\n",
        "**False Positive (FP):** It is the **frequency of recommended items that are actually not relevant**. In this case, the recommendation system is not doing a good job of finding and recommending the relevant items to the user. This would result in **loss of resources for the service provider**, which they would also like to minimize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yuvc2VaZTsnl"
      },
      "source": [
        "**Recall:** It is the **fraction of actually relevant items that are recommended to the user**, i.e., if out of 10 relevant products, 6 are recommended to the user then recall is 0.60. Higher the value of recall better is the model. It is one of the metrics to do the performance assessment of classification models.\n",
        "\n",
        "**Precision:** It is the **fraction of recommended items that are relevant actually**, i.e., if out of 10 recommended items, 6 are found relevant by the user then precision is 0.60. The higher the value of precision better is the model. It is one of the metrics to do the performance assessment of classification models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NLc36Y8Tsnm"
      },
      "source": [
        "**While making a recommendation system, it becomes customary to look at the performance of the model. In terms of how many recommendations are relevant and vice-versa, below are some most used performance metrics used in the assessment of recommendation systems.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqF8fRBqTsnm"
      },
      "source": [
        "### **Precision@k, Recall@ k, and F1-score@k**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imMJNF0HTsnm"
      },
      "source": [
        "**Precision@k** - It is the **fraction of recommended items that are relevant in `top k` predictions**. The value of k is the number of recommendations to be provided to the user. One can choose a variable number of recommendations to be given to a unique user.  \n",
        "\n",
        "\n",
        "**Recall@k** - It is the **fraction of relevant items that are recommended to the user in `top k` predictions**.\n",
        "\n",
        "**F1-score@k** - It is the **harmonic mean of Precision@k and Recall@k**. When **precision@k and recall@k both seem to be important** then it is useful to use this metric because it is representative of both of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBW4BUhWTsnm"
      },
      "source": [
        "### **Some useful functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOBHKh0eTsnm"
      },
      "source": [
        "- Below function takes the **recommendation model** as input and gives the **precision@k, recall@k, and F1-score@k** for that model.  \n",
        "- To compute **precision and recall**, **top k** predictions are taken under consideration for each user.\n",
        "- We will use the precision and recall to compute the F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxn-GahOTsnm"
      },
      "outputs": [],
      "source": [
        "def precision_recall_at_k(model, k = 10, threshold = 3.5):\n",
        "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
        "\n",
        "    # First map the predictions to each user\n",
        "    user_est_true = defaultdict(list)\n",
        "\n",
        "    # Making predictions on the test data\n",
        "    predictions = model.test(testset)\n",
        "\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "\n",
        "        # Sort user ratings by estimated value\n",
        "        user_ratings.sort(key = lambda x: x[0], reverse = True)\n",
        "\n",
        "        # Number of relevant items\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # Number of recommended items in top k\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "\n",
        "        # Number of relevant and recommended items in top k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "\n",
        "        # Precision@K: Proportion of recommended items that are relevant\n",
        "        # When n_rec_k is 0, Precision is undefined. Therefore, we are setting Precision to 0 when n_rec_k is 0\n",
        "\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "\n",
        "        # Recall@K: Proportion of relevant items that are recommended\n",
        "        # When n_rel is 0, Recall is undefined. Therefore, we are setting Recall to 0 when n_rel is 0\n",
        "\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "\n",
        "    # Mean of all the predicted precisions are calculated.\n",
        "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
        "\n",
        "    # Mean of all the predicted recalls are calculated.\n",
        "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
        "\n",
        "    accuracy.rmse(predictions)\n",
        "\n",
        "    print('Precision: ', precision) # Command to print the overall precision\n",
        "\n",
        "    print('Recall: ', recall) # Command to print the overall recall\n",
        "\n",
        "    print('F_1 score: ', round((2*precision*recall)/(precision+recall), 3)) # Formula to compute the F-1 score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZmsamDVyek-"
      },
      "source": [
        "**Hints:**\n",
        "\n",
        "- To compute **precision and recall**, a **threshold of 3.5 and k value of 10 can be considered for the recommended and relevant ratings**.\n",
        "- Think about the performance metric to choose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hxjJMTwnVNB"
      },
      "source": [
        "Below we are loading the **`rating` dataset**, which is a **pandas DataFrame**, into a **different format called `surprise.dataset.DatasetAutoFolds`**, which is required by this library. To do this, we will be **using the classes `Reader` and `Dataset`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGfYDiOCpe4X"
      },
      "outputs": [],
      "source": [
        "# Instantiating Reader scale with expected rating scale\n",
        "reader = Reader(rating_scale = (0, 5))\n",
        "# Loading the rating dataset\n",
        "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
        "# Splitting the data into train and test datasets\n",
        "trainset, testset = train_test_split(data, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmHTEt7TnVNC"
      },
      "source": [
        "Now, we are **ready to build the first baseline similarity-based recommendation system** using the cosine similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVDfVHB4tQfU"
      },
      "source": [
        "### **Building the user-user Similarity-based Recommendation System**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO3FL7iape8A",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4fe74f-52f6-4031-b6c1-634011f5961b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1.0012\n",
            "Precision:  0.855\n",
            "Recall:  0.858\n",
            "F_1 score:  0.856\n"
          ]
        }
      ],
      "source": [
        "# Declaring the similarity options\n",
        "sim_options = {\n",
        "    'name': 'cosine',\n",
        "    'user_based': True\n",
        "}\n",
        "\n",
        "# Initialize the KNNBasic model using sim_options declared, Verbose = False, and setting random_state = 1\n",
        "model = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model.fit(trainset)\n",
        "\n",
        "# Let us compute precision@k, recall@k, and f_1 score using the precision_recall_at_k function defined above\n",
        "precision_recall_at_k(model, k=10, threshold=3.5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEuJK_A9Tsnn"
      },
      "source": [
        "**Write your observations here:** The recommendation system appears to perform really well with precision, recall, and F1 score all being >= 0.85 when the maximum is 1.00."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reFD0-nsnVNC"
      },
      "source": [
        "Let's now **predict rating for a user with `userId=A3LDPF5FMB782Z` and `productId=1400501466`** as shown below. Here the user has already interacted or watched the product with productId '1400501466' and given a rating of 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxd23bZ9pe_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13fa5efc-b89d-4d0b-b580-836561c1ef3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user A3LDPF5FMB782Z on product 1400501466: 3.40\n"
          ]
        }
      ],
      "source": [
        "# Predicting rating for a sample user with an interacted product\n",
        "user_id = 'A3LDPF5FMB782Z'\n",
        "product_id = '1400501466'\n",
        "\n",
        "predicted_rating = model.predict(user_id, product_id)\n",
        "print(f\"Predicted rating for user {user_id} on product {product_id}: {predicted_rating.est:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENJcqG_wemRH"
      },
      "source": [
        "**Write your observations here:** This prediction shows that the rating should be on the lower end being around 3.4. Given that around 50% of ratings are 5 star ratings, this prediction may be slightly wrong."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj6ecbglTsno"
      },
      "source": [
        "Below is the **list of users who have not seen the product with product id \"1400501466\"**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCRBMD-RTsno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d57f9d-a913-4ca1-df6c-22e564249a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique user_id where prod_id is not equal to '1400501466':\n",
            "['A2ZR3YTMEEIIZ4' 'A3CLWR1UUZT6TG' 'A5JLAU2ARJ0BO' ... 'A215WH6RUDUCMP'\n",
            " 'A38C12950IM24P' 'A2J4XMWKR8PPD0']\n"
          ]
        }
      ],
      "source": [
        "# Find unique user_id where prod_id is not equal to \"1400501466\"\n",
        "filtered_df = df_final[df_final['prod_id'] != \"1400501466\"]\n",
        "unique_user_ids = filtered_df['user_id'].unique()\n",
        "\n",
        "print(\"Unique user_id where prod_id is not equal to '1400501466':\")\n",
        "print(unique_user_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT42ecaSTsno"
      },
      "source": [
        "* It can be observed from the above list that **user \"A2ZR3YTMEEIIZ4\" has not seen the product with productId \"1400501466\"** as this userId is a part of the above list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXSgq8OEnVNE"
      },
      "source": [
        "**Below we are predicting rating for `userId=A34BZM6S9L7QI4` and `prod_id=1400501466`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbFcBj1PpfEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1f6bcc-e576-4012-ccc3-43019f8c520a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user A34BZM6S9L7QI4 on product 1400501466: 4.29\n"
          ]
        }
      ],
      "source": [
        "# Predicting rating for a sample user with a non interacted product\n",
        "user_id = 'A34BZM6S9L7QI4'\n",
        "product_id = '1400501466'\n",
        "\n",
        "predicted_rating = model.predict(user_id, product_id)\n",
        "print(f\"Predicted rating for user {user_id} on product {product_id}: {predicted_rating.est:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02rwld8yemRI"
      },
      "source": [
        "**Write your observations here:** With a non interacted product, we see the recommendation system gives a predicted much higher rating of 4.29 which may be more accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejjof6csnVNF"
      },
      "source": [
        "### **Improving similarity-based recommendation system by tuning its hyperparameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2j4VvfQnVNF"
      },
      "source": [
        "Below, we will be tuning hyperparameters for the `KNNBasic` algorithm. Let's try to understand some of the hyperparameters of the KNNBasic algorithm:\n",
        "\n",
        "- **k** (int) – The (max) number of neighbors to take into account for aggregation. Default is 40.\n",
        "- **min_k** (int) – The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the prediction is set to the global mean of all ratings. Default is 1.\n",
        "- **sim_options** (dict) – A dictionary of options for the similarity measure. And there are four similarity measures available in surprise -\n",
        "    - cosine\n",
        "    - msd (default)\n",
        "    - Pearson\n",
        "    - Pearson baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LmPbSUSTsnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb70b379-86c2-402f-e66f-826c8724f9fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE score: 0.9705\n",
            "Best combination of parameters:\n",
            "{'k': 30, 'min_k': 5, 'sim_options': {'name': 'cosine', 'user_based': True}}\n"
          ]
        }
      ],
      "source": [
        "# Setting up parameter grid to tune the hyperparameters\n",
        "from surprise import Dataset, Reader, KNNBasic\n",
        "from surprise.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'k': [20, 30],\n",
        "    'min_k': [5],\n",
        "    'sim_options': {\n",
        "        'name': ['cosine', 'msd'],\n",
        "        'user_based': [True]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Performing 3-fold cross-validation to tune the hyperparameters\n",
        "grid_search = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
        "\n",
        "# Fitting the data\n",
        "reader = Reader(rating_scale=(0, 5))\n",
        "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
        "grid_search.fit(data)\n",
        "\n",
        "# Best RMSE score\n",
        "best_rmse = grid_search.best_score['rmse']\n",
        "print(f\"Best RMSE score: {best_rmse:.4f}\")\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "best_params = grid_search.best_params['rmse']\n",
        "print(\"Best combination of parameters:\")\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2fHNvu7nVNF"
      },
      "source": [
        "Once the grid search is **complete**, we can get the **optimal values for each of those hyperparameters**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHWgxu_YnVNG"
      },
      "source": [
        "Now, let's build the **final model by using tuned values of the hyperparameters**, which we received by using **grid search cross-validation**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PujRJA8X_JEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5c254c-e1a7-4630-b5e3-c75d93c7f4f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9510\n",
            "Precision:  0.849\n",
            "Recall:  0.893\n",
            "F_1 score:  0.87\n"
          ]
        }
      ],
      "source": [
        "# Using the optimal similarity measure for user-user based collaborative filtering\n",
        "optimized_model = KNNBasic(k=best_params['k'],\n",
        "                 min_k=best_params['min_k'],\n",
        "                 sim_options=best_params['sim_options'])\n",
        "\n",
        "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
        "reader = Reader(rating_scale=(0, 5))\n",
        "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training the algorithm on the trainset\n",
        "optimized_model.fit(trainset)\n",
        "\n",
        "# Let us compute precision@k and recall@k also with k =10\n",
        "precision_recall_at_k(optimized_model, k=10, threshold=3.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHsWvFjKTsnp"
      },
      "source": [
        "**Write your observations here:** We see that RMSE is better in this model and both Recall and F1 score have noticeable improvements while Precision very slightly declines. Overall performance, as expected, seems better with the optimized model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhcAXK0CnVNG"
      },
      "source": [
        "### **Steps:**\n",
        "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
        "- **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
        "- **Compare the output with the output from the baseline model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgV63lHiq1TV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3b32bf-6d73-4189-b768-76e3ce10b8ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized model prediction for A3LDPF5FMB782Z on prod_id 1400501466: 3.40\n"
          ]
        }
      ],
      "source": [
        "# Use sim_user_user_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId 1400501466\n",
        "predicted_rating_optimized_A3LDPF5FMB782Z = optimized_model.predict(\"A3LDPF5FMB782Z\", \"1400501466\")\n",
        "print(f\"Optimized model prediction for A3LDPF5FMB782Z on prod_id 1400501466: {predicted_rating_optimized_A3LDPF5FMB782Z.est:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXO2Ztjhq1bN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66cc16d-c029-41a0-c133-bbe1d45c02e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized model prediction for A34BZM6S9L7QI4 on prod_id 1400501466: 4.29\n"
          ]
        }
      ],
      "source": [
        "# Use sim_user_user_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
        "predicted_rating_optimized_A34BZM6S9L7QI4 = optimized_model.predict(\"A34BZM6S9L7QI4\", \"1400501466\")\n",
        "print(f\"Optimized model prediction for A34BZM6S9L7QI4 on prod_id 1400501466: {predicted_rating_optimized_A34BZM6S9L7QI4.est:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5i-OPprNF2e"
      },
      "source": [
        "**Write your observations here:** The exact same predictions were given with the optimized model and the baseline model, so it seems that the models may both be accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op_zwO_FnVNH"
      },
      "source": [
        "### **Identifying similar users to a given user (nearest neighbors)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2QsfqhanVNH"
      },
      "source": [
        "We can also find out **similar users to a given user** or its **nearest neighbors** based on this KNNBasic algorithm. Below, we are finding the 5 most similar users to the first user in the list with internal id 0, based on the `msd` distance metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbFle7cKmBJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b7eb42-d0f5-4bba-99bd-df0e15fd8b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "The 5 most similar users to user with internal id 0 are: ['A16J281SJ9QXIQ', 'A3CJ7MHAS9IMAM', 'A2L0F2T1DLTNT8', 'AYMD77ITD15PT', 'A21I62TCDL4754']\n"
          ]
        }
      ],
      "source": [
        "# 0 is the inner id of the above user\n",
        "reader = Reader(rating_scale=(0, 5))\n",
        "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "sim_options = {\n",
        "    'name': 'msd',\n",
        "    'user_based': True\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "knn_msd = KNNBasic(sim_options=sim_options)\n",
        "knn_msd.fit(trainset)\n",
        "\n",
        "neighbors = knn_msd.get_neighbors(0, k=5)\n",
        "\n",
        "similar_users = [trainset.to_raw_uid(neighbor) for neighbor in neighbors]\n",
        "\n",
        "# Display the similar users\n",
        "print(f\"The 5 most similar users to user with internal id 0 are: {similar_users}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0NsrX_anVNH"
      },
      "source": [
        "### **Implementing the recommendation algorithm based on optimized KNNBasic model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3ESobDynVNI"
      },
      "source": [
        "Below we will be implementing a function where the input parameters are:\n",
        "\n",
        "- data: A **rating** dataset\n",
        "- user_id: A user id **against which we want the recommendations**\n",
        "- top_n: The **number of products we want to recommend**\n",
        "- algo: the algorithm we want to use **for predicting the ratings**\n",
        "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW9V1Tk65HlY"
      },
      "outputs": [],
      "source": [
        "def get_recommendations(data, user_id, top_n, algo):\n",
        "\n",
        "    # Creating an empty list to store the recommended product ids\n",
        "    recommendations = []\n",
        "\n",
        "    # Creating an user item interactions matrix\n",
        "    user_item_interactions_matrix = data.pivot(index = 'user_id', columns = 'prod_id', values = 'rating')\n",
        "\n",
        "    # Extracting those product ids which the user_id has not interacted yet\n",
        "    non_interacted_products = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
        "\n",
        "    # Looping through each of the product ids which user_id has not interacted yet\n",
        "    for item_id in non_interacted_products:\n",
        "\n",
        "        # Predicting the ratings for those non interacted product ids by this user\n",
        "        est = algo.predict(user_id, item_id).est\n",
        "\n",
        "        # Appending the predicted ratings\n",
        "        recommendations.append((item_id, est))\n",
        "\n",
        "    # Sorting the predicted ratings in descending order\n",
        "    recommendations.sort(key = lambda x: x[1], reverse = True)\n",
        "\n",
        "    return recommendations[:top_n] # Returing top n highest predicted rating products for this user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj_S7kh4nVNI"
      },
      "source": [
        "**Predicting top 5 products for userId = \"A3LDPF5FMB782Z\" with similarity based recommendation system**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWbR85mI5Hrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ae2581-d449-4d86-b43d-2cfc85c492fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "[('1400599997', 5), ('B00000DM9W', 5), ('B00000K4KH', 5), ('B00001W0DI', 5), ('B00002EQCW', 5)]\n"
          ]
        }
      ],
      "source": [
        "# Making top 5 recommendations for user_id \"A3LDPF5FMB782Z\" with a similarity-based recommendation engine\n",
        "sim_options = {\n",
        "    'name': 'cosine',\n",
        "    'user_based': True\n",
        "}\n",
        "knn_algo = KNNBasic(sim_options=sim_options)\n",
        "knn_algo.fit(trainset)\n",
        "top_5_recommendations = get_recommendations(df_final, \"A3LDPF5FMB782Z\", top_n=5, algo=knn_algo)\n",
        "print(top_5_recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5WfIX0Z6_q2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c45513-d957-47d6-b279-4f3b032bf4ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame of top 5 product recommendations:\n",
            "      prod_id  predicted_ratings\n",
            "0  1400599997                  5\n",
            "1  B00000DM9W                  5\n",
            "2  B00000K4KH                  5\n",
            "3  B00001W0DI                  5\n",
            "4  B00002EQCW                  5\n"
          ]
        }
      ],
      "source": [
        "# Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
        "recommendations_df = pd.DataFrame(top_5_recommendations, columns=[\"prod_id\", \"predicted_ratings\"])\n",
        "\n",
        "print(\"DataFrame of top 5 product recommendations:\")\n",
        "print(recommendations_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgbzJKk7Tsnr"
      },
      "source": [
        "### **Item-Item Similarity-based Collaborative Filtering Recommendation System**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTJu_2hcTsnr"
      },
      "source": [
        "* Above we have seen **similarity-based collaborative filtering** where similarity is calculated **between users**. Now let us look into similarity-based collaborative filtering where similarity is seen **between items**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5RMcdzjTsns",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eec0b8e-0ecd-4755-eb91-01d9bd3646f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9950\n",
            "Precision:  0.838\n",
            "Recall:  0.845\n",
            "F_1 score:  0.841\n"
          ]
        }
      ],
      "source": [
        "# Declaring the similarity options\n",
        "sim_options = {\n",
        "    'name': 'cosine',\n",
        "    'user_based': False\n",
        "}\n",
        "\n",
        "# KNN algorithm is used to find desired similar items. Use random_state=1\n",
        "knn_algo = KNNBasic(sim_options=sim_options, random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset, and predict ratings for the test set\n",
        "reader = Reader(rating_scale=(0, 5))\n",
        "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "knn_algo.fit(trainset)\n",
        "predictions = knn_algo.test(testset)\n",
        "\n",
        "# Let us compute precision@k, recall@k, and f_1 score with k = 10\n",
        "precision_recall_at_k(knn_algo, k=10, threshold=3.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni9LoeUVTsns"
      },
      "source": [
        "**Write your observations here:** This model has a relatively high RMSE, and lower F1, recall, and precision compared to previous models but still work well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFbcDQmxTsns"
      },
      "source": [
        "Let's now **predict a rating for a user with `userId = A3LDPF5FMB782Z` and `prod_Id = 1400501466`** as shown below. Here the user has already interacted or watched the product with productId \"1400501466\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsF-aaWYTsns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a1e86f2-8b88-4fca-c509-f9f8817a41a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 'A3LDPF5FMB782Z' on product '1400501466': 4.27\n"
          ]
        }
      ],
      "source": [
        "# Predicting rating for a sample user with an interacted product\n",
        "\n",
        "predicted_rating = knn_algo.predict(uid=\"A3LDPF5FMB782Z\", iid=\"1400501466\")\n",
        "\n",
        "# Displaying the predicted rating\n",
        "print(f\"Predicted rating for user 'A3LDPF5FMB782Z' on product '1400501466': {predicted_rating.est:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h0OyDMFTsns"
      },
      "source": [
        "**Write your observations here:** This time we got a much different score for A3LDPF5FMB782Z with this one being around 4.27 compared to the previous 3.40 score showing an expected increase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqKGZoAtTsns"
      },
      "source": [
        "Below we are **predicting rating for the `userId = A34BZM6S9L7QI4` and `prod_id = 1400501466`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yILOxXRTsns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99a76c66-e1dd-4469-c884-64588e1a9fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 'A34BZM6S9L7QI4' on product '1400501466': 4.29\n"
          ]
        }
      ],
      "source": [
        "# Predicting rating for a sample user with a non interacted product\n",
        "\n",
        "predicted_rating = knn_algo.predict(uid=\"A34BZM6S9L7QI4\", iid=\"1400501466\")\n",
        "\n",
        "# Displaying the predicted rating\n",
        "print(f\"Predicted rating for user 'A34BZM6S9L7QI4' on product '1400501466': {predicted_rating.est:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDKaAveJTsns"
      },
      "source": [
        "**Write your observations here:** This score is once again the same as the previous models', both optimized and not optimized, scores showing great precision in this prediction across all models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meSvpNLj_EjD"
      },
      "source": [
        "### **Hyperparameter tuning the item-item similarity-based model**\n",
        "- Use the following values for the param_grid and tune the model.\n",
        "  - 'k': [10, 20, 30]\n",
        "  - 'min_k': [3, 6, 9]\n",
        "  - 'sim_options': {'name': ['msd', 'cosine']\n",
        "  - 'user_based': [False]\n",
        "- Use GridSearchCV() to tune the model using the 'rmse' measure\n",
        "- Print the best score and best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5bcZ3HgTsnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71901a63-8fa0-45d5-c8b9-e07b74b4a873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE score: 0.9755\n",
            "Best combination of parameters:\n",
            "{'k': 30, 'min_k': 6, 'sim_options': {'name': 'msd', 'user_based': False}}\n"
          ]
        }
      ],
      "source": [
        "# Setting up parameter grid to tune the hyperparameters\n",
        "param_grid = {\n",
        "    'k': [10, 20, 30],\n",
        "    'min_k': [3, 6, 9],\n",
        "    'sim_options': {\n",
        "        'name': ['msd', 'cosine'],\n",
        "        'user_based': [False]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Performing 3-fold cross validation to tune the hyperparameters\n",
        "grid_search = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
        "\n",
        "# Fitting the data\n",
        "reader = Reader(rating_scale=(0, 5))\n",
        "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
        "grid_search.fit(data)\n",
        "\n",
        "# Find the best RMSE score\n",
        "best_rmse = grid_search.best_score['rmse']\n",
        "print(f\"Best RMSE score: {best_rmse:.4f}\")\n",
        "\n",
        "# Find the combination of parameters that gave the best RMSE score\n",
        "best_params = grid_search.best_params['rmse']\n",
        "print(\"Best combination of parameters:\")\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1psOlx6zTsnt"
      },
      "source": [
        "Once the **grid search** is complete, we can get the **optimal values for each of those hyperparameters as shown above.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrSTaQemTsnt"
      },
      "source": [
        "Now let's build the **final model** by using **tuned values of the hyperparameters** which we received by using grid search cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOS9Dwnd_LN6"
      },
      "source": [
        "### **Use the best parameters from GridSearchCV to build the optimized item-item similarity-based model. Compare the performance of the optimized model with the baseline model.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSeiM1qeTsnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db752f6-9db5-4135-9f33-2e545deed9d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9576\n",
            "Precision:  0.839\n",
            "Recall:  0.88\n",
            "F_1 score:  0.859\n"
          ]
        }
      ],
      "source": [
        "# Using the optimal similarity measure for item-item based collaborative filtering\n",
        "knn_optimized = KNNBasic(\n",
        "    k=best_params['k'],\n",
        "    min_k=best_params['min_k'],\n",
        "    sim_options=best_params['sim_options']\n",
        ")\n",
        "\n",
        "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
        "knn_optimized.fit(trainset)\n",
        "\n",
        "# Training the algorithm on the trainset\n",
        "predictions = knn_optimized.test(testset)\n",
        "\n",
        "# Let us compute precision@k and recall@k, f1_score and RMSE\n",
        "precision_recall_at_k(knn_optimized, k=10, threshold=3.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCXKnMI8Tsnt"
      },
      "source": [
        "**Write your observations here:** The optimized model increased its performance from baseline in nearly every category of the similarity matrix. RMSE was noticeably reduced to 0.9579 while recall and F_1 score had a noticeable increase in performance and precision is roughly the same in both models. Overall, there seems to be an assured increase in the model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbcj_H94Tsnt"
      },
      "source": [
        "### **Steps:**\n",
        "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
        "- **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
        "- **Compare the output with the output from the baseline model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIBRRvdoTsnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfeda278-f197-4825-ca6b-859a70696368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 'A3LDPF5FMB782Z' on product '1400501466': 4.67\n"
          ]
        }
      ],
      "source": [
        "# Use sim_item_item_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
        "predicted_rating = knn_optimized.predict(uid=\"A3LDPF5FMB782Z\", iid=\"1400501466\")\n",
        "\n",
        "# Displaying the predicted rating\n",
        "print(f\"Predicted rating for user 'A3LDPF5FMB782Z' on product '1400501466': {predicted_rating.est:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUMieM_l6R0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a36f863-407c-4da8-f6c0-c803211fcdb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 'A34BZM6S9L7QI4' on product '1400501466': 4.29\n"
          ]
        }
      ],
      "source": [
        "# Use sim_item_item_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
        "predicted_rating = knn_optimized.predict(uid=\"A34BZM6S9L7QI4\", iid=\"1400501466\")\n",
        "\n",
        "# Displaying the predicted rating\n",
        "print(f\"Predicted rating for user 'A34BZM6S9L7QI4' on product '1400501466': {predicted_rating.est:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyMi-Dsi6R0l"
      },
      "source": [
        "**Write your observations here:** For A3LDPF5FMB782Z, the optimized model had an even higher expected rating than the baseline model which already had a high prediction in rating with the optimized model predicting 4.67 and baseline being 4.27. For A34BZM6S9L7QI4, the model performance once again stayed the same as it has for every model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDlNB7tnTsnu"
      },
      "source": [
        "### **Identifying similar items to a given item (nearest neighbors)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLdDiFA6Tsnu"
      },
      "source": [
        "We can also find out **similar items** to a given item or its nearest neighbors based on this **KNNBasic algorithm**. Below we are finding the 5 most similar items to the item with internal id 0 based on the `msd` distance metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRJS4oDFTsnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf13aa6-2004-49b7-ff98-7cfc4f20fb8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "The 5 most similar items to the item with internal id 0 are: ['B008X9Z3UC', 'B003ZSHKJ8', 'B003LSTD38', 'B005EOWBKE', 'B004IZN3WU']\n"
          ]
        }
      ],
      "source": [
        "sim_options = {\n",
        "    'name': 'msd',\n",
        "    'user_based': False  # Item-item collaborative filtering\n",
        "}\n",
        "\n",
        "knn_msd = KNNBasic(sim_options=sim_options)\n",
        "knn_msd.fit(trainset)\n",
        "\n",
        "neighbors = knn_msd.get_neighbors(0, k=5)\n",
        "\n",
        "similar_items = [trainset.to_raw_iid(neighbor) for neighbor in neighbors]\n",
        "print(f\"The 5 most similar items to the item with internal id 0 are: {similar_items}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IuRbcjm6R0m"
      },
      "source": [
        "**Predicting top 5 products for userId = \"A1A5KUIIIHFF4U\" with similarity based recommendation system.**\n",
        "\n",
        "**Hint:** Use the get_recommendations() function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzoEbuZFTsnu"
      },
      "outputs": [],
      "source": [
        "# Making top 5 recommendations for user_id A1A5KUIIIHFF4U with similarity-based recommendation engine.\n",
        "top_5_recommendations = get_recommendations(df_final, \"A1A5KUIIIHFF4U\", top_n=5, algo=knn_msd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kXVTiysTsnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dcf4237-7b09-4947-ae71-61d062ee2507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 product recommendations for user 'A1A5KUIIIHFF4U':\n",
            "      prod_id  predicted_ratings\n",
            "0  9983891212                  5\n",
            "1  B00000J1V5                  5\n",
            "2  B00000K4KH                  5\n",
            "3  B00001WRSJ                  5\n",
            "4  B00003006R                  5\n"
          ]
        }
      ],
      "source": [
        "# Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
        "recommendations_df = pd.DataFrame(top_5_recommendations, columns=[\"prod_id\", \"predicted_ratings\"])\n",
        "\n",
        "print(\"Top 5 product recommendations for user 'A1A5KUIIIHFF4U':\")\n",
        "print(recommendations_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHzmYvs0Tsnv"
      },
      "source": [
        "Now as we have seen **similarity-based collaborative filtering algorithms**, let us now get into **model-based collaborative filtering algorithms**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKgJpSA9vOOL"
      },
      "source": [
        "### **Model 3: Model-Based Collaborative Filtering - Matrix Factorization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF6ZGyqhCAob"
      },
      "source": [
        "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4Otha8ovOOL"
      },
      "source": [
        "### Singular Value Decomposition (SVD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sGl3QkLvOOL"
      },
      "source": [
        "SVD is used to **compute the latent features** from the **user-item matrix**. But SVD does not work when we **miss values** in the **user-item matrix**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07-2PT5Ssjqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5fb93e0-c739-48e5-be1d-cccce0382cdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8882\n",
            "Precision:  0.853\n",
            "Recall:  0.88\n",
            "F_1 score:  0.866\n"
          ]
        }
      ],
      "source": [
        "# Using SVD matrix factorization. Use random_state = 1\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "from surprise import accuracy\n",
        "\n",
        "reader = Reader(rating_scale=(0, 5))\n",
        "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "svd = SVD(random_state=1)\n",
        "\n",
        "# Training the algorithm on the trainset\n",
        "svd.fit(trainset)\n",
        "\n",
        "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
        "precision_recall_at_k(svd, k=10, threshold=3.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ6fTuCDnVNL"
      },
      "source": [
        "**Write your observations here:** SVD has given the least RMSE out of any model and has a strong recall and F1 score and good precision. Really good performance for the baseline model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqFmW5i16R0n"
      },
      "source": [
        "**Let's now predict the rating for a user with `userId = \"A3LDPF5FMB782Z\"` and `prod_id = \"1400501466`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWIhfdxXsjqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eb27148-55ab-475c-d90f-c15b6ce7d079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 'A3LDPF5FMB782Z' on product '1400501466': 4.08\n"
          ]
        }
      ],
      "source": [
        "# Making prediction\n",
        "predicted_rating = svd.predict(uid=\"A3LDPF5FMB782Z\", iid=\"1400501466\")\n",
        "\n",
        "# Displaying the predicted rating\n",
        "print(f\"Predicted rating for user 'A3LDPF5FMB782Z' on product '1400501466': {predicted_rating.est:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIjzqDY5nVNM"
      },
      "source": [
        "**Write your observations here:** This model gave an expected rating of 4.08 for user A3LDPF5FMB782Z, which is in the middle of the ratings compared to the previous models, baseline and optimized, that were tested."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1aYxVeMnVNM"
      },
      "source": [
        "**Below we are predicting rating for the `userId = \"A34BZM6S9L7QI4\"` and `productId = \"1400501466\"`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APm-uMSvcAMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3012c2-e48a-418b-f0a8-1d3d861c886c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 'A34BZM6S9L7QI4' on product '1400501466': 4.40\n"
          ]
        }
      ],
      "source": [
        "# Making prediction\n",
        "predicted_rating = svd.predict(uid=\"A34BZM6S9L7QI4\", iid=\"1400501466\")\n",
        "\n",
        "# Displaying the predicted rating\n",
        "print(f\"Predicted rating for user 'A34BZM6S9L7QI4' on product '1400501466': {predicted_rating.est:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEL6dy3wnVNM"
      },
      "source": [
        "**Write your observations here:** This model is the first one that gave a different expected rating for user A34BZM6S9L7QI4 as all of the previous models gave this user an expected rating of 4.29. This model predicts 4.40, which is now higher, and the highest of all the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x13Eb9Owvpcw"
      },
      "source": [
        "### **Improving Matrix Factorization based recommendation system by tuning its hyperparameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQcDPhhcnVNN"
      },
      "source": [
        "Below we will be tuning only three hyperparameters:\n",
        "- **n_epochs**: The number of iterations of the SGD algorithm.\n",
        "- **lr_all**: The learning rate for all parameters.\n",
        "- **reg_all**: The regularization term for all parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bM81V_hvtwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce92166b-609e-48c8-af79-037ea18d6200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE score: 0.8981\n",
            "Best combination of parameters:\n",
            "{'n_epochs': 20, 'lr_all': 0.01, 'reg_all': 0.4}\n"
          ]
        }
      ],
      "source": [
        "# Set the parameter space to tune\n",
        "param_grid = {\n",
        "    'n_epochs': [10, 20, 30],\n",
        "    'lr_all': [0.001, 0.005, 0.01],\n",
        "    'reg_all': [0.2, 0.4, 0.6]\n",
        "}\n",
        "\n",
        "# Performing 3-fold gridsearch cross-validation\n",
        "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
        "\n",
        "# Fitting data\n",
        "grid_search.fit(data)\n",
        "\n",
        "# Best RMSE score\n",
        "best_rmse = grid_search.best_score['rmse']\n",
        "print(f\"Best RMSE score: {best_rmse:.4f}\")\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "best_params = grid_search.best_params['rmse']\n",
        "print(\"Best combination of parameters:\")\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzY78HsrnVNO"
      },
      "source": [
        "Now, we will **the build final model** by using **tuned values** of the hyperparameters, which we received using grid search cross-validation above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA_7xe-nnhuu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4189e6d4-ea6c-4e8f-e76e-431280cdc371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8822\n",
            "Precision:  0.854\n",
            "Recall:  0.884\n",
            "F_1 score:  0.869\n"
          ]
        }
      ],
      "source": [
        "# Build the optimized SVD model using optimal hyperparameter search. Use random_state=1\n",
        "svd_optimized = SVD(n_epochs=best_params['n_epochs'],\n",
        "                    lr_all=best_params['lr_all'],\n",
        "                    reg_all=best_params['reg_all'],\n",
        "                    random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "svd_optimized.fit(trainset)\n",
        "\n",
        "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
        "precision_recall_at_k(svd_optimized, k=10, threshold=3.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HJvPsjITsny"
      },
      "source": [
        "**Write your observations here:** Overall, not a whole lot changed between the baseline and optimized models, but there are slight increases in performance everywhere for the optimized model. RMSE is slightly lower in the optimized SVD model, and there were very slight increases in Precision, Recall, and F_1 score. Overall the optimization did elevate the models performance but not at a significant level."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x36MgO66R0o"
      },
      "source": [
        "### **Steps:**\n",
        "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
        "- **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
        "- **Compare the output with the output from the baseline model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_IiT4dW6R0o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e558d66-41a3-453f-b144-0b9484cfe665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 'A3LDPF5FMB782Z' on product '1400501466': 4.04\n"
          ]
        }
      ],
      "source": [
        "# Use svd_algo_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
        "predicted_rating = svd_optimized.predict(uid=\"A3LDPF5FMB782Z\", iid=\"1400501466\")\n",
        "\n",
        "# Displaying the predicted rating\n",
        "print(f\"Predicted rating for user 'A3LDPF5FMB782Z' on product '1400501466': {predicted_rating.est:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVLEXRiA6R0o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2576350-99bc-47be-9d8f-54f88034bacc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 'A34BZM6S9L7QI4' on product '1400501466': 4.17\n"
          ]
        }
      ],
      "source": [
        "# Use svd_algo_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
        "predicted_rating = svd_optimized.predict(uid=\"A34BZM6S9L7QI4\", iid=\"1400501466\")\n",
        "\n",
        "# Displaying the predicted rating\n",
        "print(f\"Predicted rating for user 'A34BZM6S9L7QI4' on product '1400501466': {predicted_rating.est:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For both users, the optimized SVD had a lower predicted rating. For user A3LDPF5FMB782Z, the predicted rating only slightly lowered, going from 4.08 to 4.04 but for user A34BZM6S9L7QI4, the rating significantly lowered going from 4.40 to 4.17. It seems that the optmization led to a decrease in its estimate of predicted ratings."
      ],
      "metadata": {
        "id": "ghjw3SjTy5Ox"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnwPwgjB8DwS"
      },
      "source": [
        "### **Conclusion and Recommendations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuqnifw9NF2p"
      },
      "source": [
        "**Write your conclusion and recommendations here**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use SVD as the foremost model:\n",
        "The SVD model, especially after optimization, provides the best balance between accuracy (as indicated by RMSE) and recommendation quality (as indicated by precision, recall, and F1 score). It is best to deploy the optimized SVD model for personalized product recommendations on the platform.\n",
        "\n",
        "# Attempt Hybridization with Collaborative Filtering and SVD:\n",
        "While SVD should be the primary model, the collaborative filtering models (both user-user and item-item) could be used as supplementary models. These models can provide diverse recommendations that might not be captured by SVD alone, especially in cases where the user-item interaction matrix is sparse or when new items are added to the platform.\n",
        "\n",
        "# Rank-based Recommendations may be best for newer users:\n",
        "The rank-based recommendation model can be useful for new users with little to no interaction history (cold start problem). By recommending top-rated products, the system can still provide value to these users while they build up their interaction history for more personalized recommendations.\n",
        "\n",
        "# Improved UI/ User Experience:\n",
        "By deploying a well-tuned recommendation system, Amazon can significantly enhance user engagement, as users are more likely to interact with products that are relevant to their interests.\n",
        "\n",
        "# Better business model/ Increases in Revenue:\n",
        "Personalized recommendations have a direct impact on sales. By suggesting products that users are more likely to purchase, the system can drive higher conversion rates and increase revenue."
      ],
      "metadata": {
        "id": "lYyRN3FYzP0B"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}